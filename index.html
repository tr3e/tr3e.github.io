<!DOCTYPE html>
<html lang="cx">

<head>
  <title>Han Liang - ShanghaiTech</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="utf-8" />
  <meta name="keywords" content="" />
  <script>
    addEventListener("load", function () {
      setTimeout(hideURLbar, 0);
    }, false);

    function hideURLbar() {
      window.scrollTo(0, 1);
    }
  </script>
  <!-- Custom Theme files -->
  <link href="css/bootstrap.css" type="text/css" rel="stylesheet" media="all">
  <link href="css/style.css" type="text/css" rel="stylesheet" media="all">
  <!-- font-awesome icons -->
  <link href="css/fontawesome-all.min.css" rel="stylesheet">
  <!-- //Custom Theme files -->
  <!-- online-fonts -->
  <link href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400,600,700,900" rel="stylesheet">
  <!-- //online-fonts -->
  <style>
	#news-box {
	height: 75px;
	overflow: hidden;
}
#news-box-more{
	font-size: 14px;
}

  </style>
</head>

<body>
  <div class="sidenav">
    <div class="side_top"> <img src="images/lianghan.png" width="75%" alt="news image" class="img-fluid navimg">
      <h1> Han Liang - 梁瀚 <br>
        <!--[CV - <a href="files/CV/chenxin_cv_cn_201803.pdf"><font size="4">中文</font></a> / <a href="files/CV/chenxin_cv_en_202007.pdf">English</a>]<br>-->
        <!--[CV - <font size="4">中文</font>/ <a href="files/CV/chenxin_cv_en_202011.pdf">English</a>]<br>-->
        [<a href="">Download CV</a>]<br>
        [<a href="mailto:lianghan@shanghaitech.edu.cn">Email</a> | <a href="https://github.com/tr3e">GitHub</a> |
        <a href="">LinkedIn</a>]
        [<a href="https://aideadlin.es/?sub=ML,CV,NLP,RO,SP,DM">Conference Timer</a>]
      </h1>
    </div>
    <!-- header -->
    <header>
      <div class="container-fluid px-5 ">
        <nav class="mnu mx-auto">
          <label for="drop" class="toggle">Menu</label>
          <input type="checkbox" id="drop">
          <ul class="menu">
            <!--<li><a href="index.html">Home</a></li-->
            <li class="mt-sm-0"><a href="#about" class="scroll">Bio</a></li>
            <li class="mt-sm-3"><a href="#publication" class="scroll">Publications</a></li>
            <li class="mt-sm-3"><a href="#experience" class="scroll">Experience</a></li>
            <li class="mt-sm-3"><a href="#skill" class="scroll">Skills</a></li>
          </ul>
        </nav>
      </div>
    </header>
  </div>
  <div class="main" id="about">
    <div class="banner-text-w3ls">
      <div>
        <div class="mx-auto text-left">
          <h1><strong>Han Liang - 梁瀚</strong></h1>
          <h4>Ph.D. Candidate</h4>
          <h6>lianghan@shanghaitech.edu.cn</h6><br>
          <h4><a href="https://www.shanghaitech.edu.cn/eng/"><b>ShanghaiTech University - 上海科技大学 </b></a> - <a
              href="http://sist.shanghaitech.edu.cn/">SIST</a> - <a
              href="http://vic.shanghaitech.edu.cn/">VDI</a></h4>
          <h4><a href="https://en.uestc.edu.cn/"><b>University of Electronic Science and Technology of China - 电子科技大学 </b></a></h4> <br>

          <h5>Hi, I am currently a PhD candidate in computer science at VRVC Lab, <a
            href="http://www.shanghaitech.edu.cn/eng/">ShanghaiTech University</a>, advised by <a
            href="http://www.xu-lan.com/">Prof. Lan Xu</a> and <a
            href="http://www.yu-jingyi.com/">Prof. Jingyi Yu</a>. <br>
            Before that, I obtained my B.E. in software engineering from <a
            href="https://en.uestc.edu.cn/">UESTC</a>.
            <br><br>

            My research focuses on the intersection of <strong> graphics</strong>, <strong> vision</strong> and <strong> robotics</strong>. <br>
            My goal is to build human-centric intelligent agents that perform and perceive in the complex virtual/real world.<br>
            My current research Interests include: 
          </p>
          <li>character animation</li>
          <li>performance understanding</li>
          <li>LLM-based motive intelligence</li></h5>
          <br>
          <font color="#f33"><b>News!</b></font>
          </p>
           <div id="news-box">
            <li>[2023.01]&ensp; LiDAR-aid Inertial Poser is accepted by TVCG 2023.</li>
            <li>[2022.11]&ensp; HybridCap is accepted by AAAI 2023 (Oral).</li>
            <li>[2021.03]&ensp; ChallenCap is accepted by CVPR 2021 (Oral).</li>
		       </div>
		        <a id="news-box-more" href="javascript:;"style="font-size:16px;"><b>MORE >></b></a>
            <br><br>
            <b>Services</b>
            </p>
             <div id="news-box">
              <li>Conference Reviewer: ICCV, CVPR, AAAI, WACV</li>
             </div>
        </div>
      </div>
    </div>



    <!-- publications -->
    <section class="publication" id="publication">
      <div class="container-fluid py-lg-1">
        <h3 class="w3_head mb-5">Publications <font size ="5"></font></h3>
        <!-- <h3 class="w3_head mb-5">Selected Publications (<a href="./Publication.html">Complete List…</a>)</h3> -->
        <div class="col-lg-12">
          <div class="row paper-box">
            <div class="col-md-3 col-12 paper_img"> 
              <video 
                src="pubs/omg/omg-teaser.mp4" width="90%" playsinline=""
                autoplay="autoplay" loop="loop" preload="" muted="" alt="Popup Image" class="img-fluid" />
              </div>
       
            <div class="col-md-9 col-12 paper-content">
              <h4>	
                <strong>OMG</strong>: Towards Open-vocabulary Motion Generation via Mixture of Controllers<br>
              </h4>
              <p><strong>Han Liang</strong>, Jiacheng Bao, Ruichi Zhang, Sihan Ren, Yuecheng Xu, Sibei Yang, Xin Chen, Jingyi Yu, Lan Xu<br>
              </p>
              <p>(<strong>Arxiv 2023 Preprint</strong>)</p>
              <p>
                [<a href="https://tr3e.github.io/omg-page/">Webpage</a> |
                <a href="https://arxiv.org/pdf/2312.08985.pdf">Paper</a> |
                <a href="https://arxiv.org/abs/2312.08985">Arxiv</a> |
                <a href="https://www.youtube.com/watch?v=1M4c2eZFTk0">Video</a> |
                <a href="">Code</a>]
              </p>
            </div>
       
          </div>


          <div class="row paper-box">
            <div class="col-md-3 col-12 paper_img"> 
              <video 
                src="pubs/intergen/intergen.mp4" width="90%" playsinline=""
                autoplay="autoplay" loop="loop" preload="" muted="" alt="Popup Image" class="img-fluid" />
              </div>
            <!-- .Icon ends here -->
            <div class="col-md-9 col-12 paper-content">
              <h4><strong>InterGen</strong>: Diffusion-based Multi-human Motion Generation under Complex Interactions<br>
              </h4>
              <p><strong>Han Liang</strong>, Wenqian Zhang, Wenxuan Li, Jingyi Yu, Lan Xu<br>
              </p>
              <p>(<strong>Arxiv 2023 Preprint</strong>)</p>
              <!-- <p class="text-left">We present TightCap, a data-driven scheme to capture both the human shape and dressed garments accurately with only a single 3D human scan. </p> -->
              <p>
                [<a href="https://tr3e.github.io/intergen-page/">Webpage</a> |
                <a href="https://arxiv.org/pdf/2304.05684.pdf">Paper</a> |
                <a href="https://arxiv.org/abs/2304.05684">Arxiv</a> |
                <a href="https://www.youtube.com/watch?v=1M4c2eZFTk0">Video</a> |
                <a href="https://github.com/tr3e/InterGen">Code</a>]
              </p>
            </div>
            <!-- .Service-content ends here -->
          </div>


          <div class="row paper-box">
            <div class="col-md-3 col-12 paper_img"> 
              <video 
                src="pubs/hybridcap/hybridcap.mp4" width="90%" playsinline=""
                autoplay="autoplay" loop="loop" preload="" muted="" alt="Popup Image" class="img-fluid" />
              </div>
            <!-- .Icon ends here -->
            <div class="col-md-9 col-12 paper-content">
              <h4><strong>HybridCap</strong>: Inertia-aid monocular capture of challenging human motions<br>
              </h4>
              <p><strong>Han Liang</strong>, Yannan He, Chengfeng Zhao, Mutian Li, Jingya Wang, Jingyi Yu, Lan Xu<br>
              </p>
              <p>(<strong>AAAI 2023  Oral</strong>)</p>
              <!-- <p class="text-left">We present TightCap, a data-driven scheme to capture both the human shape and dressed garments accurately with only a single 3D human scan. </p> -->
              <p>
                [<a href="https://tr3e.github.io/omg-page/">Webpage</a> |
                <a href="https://dl.acm.org/doi/10.1609/aaai.v37i2.25240">Paper</a> |
                <a href="https://arxiv.org/abs/2203.09287">Arxiv</a> |
                <a href="https://www.youtube.com/watch?v=fV4IRTUdSws&t=84s">Video</a>]
              </p>
            </div>
            <!-- .Service-content ends here -->
          </div>

          <div class="row paper-box">
            <div class="col-md-3 col-12 paper_img"> 
              <video 
                src="pubs/lip/lip.mp4" width="90%" playsinline=""
                autoplay="autoplay" loop="loop" preload="" muted="" alt="Popup Image" class="img-fluid" />
              </div>
            <!-- .Icon ends here -->
            <div class="col-md-9 col-12 paper-content">
              <h4><strong>LiDAR-aid Inertial Poser</strong>: Large-scale Human Motion Capture by Sparse Inertial and LiDAR Sensors<br>
              </h4>
              <p>Yiming Ren, Chengfeng Zhao, Yannan He, Peishan Cong, <strong>Han Liang</strong>, Jingyi Yu, Lan Xu, Yuexin Ma<br>
              </p>
              <p>(<strong>TVCG 2023</strong>)</p>
              <!-- <p class="text-left">We present TightCap, a data-driven scheme to capture both the human shape and dressed garments accurately with only a single 3D human scan. </p> -->
              <p>
                [<a href="https://tr3e.github.io/omg-page/">Webpage</a> |
                <a href="https://dl.acm.org/doi/10.1109/TVCG.2023.3247088">Paper</a> |
                <a href="https://arxiv.org/abs/2205.15410">Arxiv</a> |
                <a href="https://www.youtube.com/watch?v=ao9eTGPQT6k">Video</a>]
              </p>
            </div>
            <!-- .Service-content ends here -->
          </div>

          <div class="row paper-box">
            <div class="col-md-3 col-12 paper_img"> 
              <video 
                src="pubs/challencap/challencap.mp4" width="90%" playsinline=""
                autoplay="autoplay" loop="loop" preload="" muted="" alt="Popup Image" class="img-fluid" />
              </div>
            <!-- .Icon ends here -->
            <div class="col-md-9 col-12 paper-content">
              <h4><strong>ChallenCap</strong>: Monocular 3d capture of challenging human performances using multi-modal references<br>
              </h4>
              <p>Yannan He, Anqi Pang, Xin Chen, <strong>Han Liang</strong>, Minye Wu, Yuexin Ma, Lan Xu<br>
              </p>
              <p>(<strong>CVPR 2021 Oral</strong>)</p>
              <!-- <p class="text-left">We propose SportsCap – the first approach for simultaneously capturing 3D human motions and understanding fine-grained actions from monocular challenging sports video input. </p> -->
              <p>
                [<a href="https://tr3e.github.io/omg-page/">Webpage</a> |
                <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/He_ChallenCap_Monocular_3D_Capture_of_Challenging_Human_Performances_Using_Multi-Modal_CVPR_2021_paper.pdf">Paper</a> |
                <a href="https://arxiv.org/abs/2103.06747">Arxiv</a> |
                <a href="https://www.youtube.com/watch?v=VBRtzfKD9II">Video</a>] <br><br><br><br>

              </p>
            </div>
            <!-- .Service-content ends here -->
          </div>
      </div>
    </section>

    <!-- publications -->
    <section class="publication" id="publication">
      <div class="container-fluid py-lg-1">
        <h3 class="w3_head mb-5">Projects <font size ="5"></font></h3>
        <!-- <h3 class="w3_head mb-5">Selected Publications (<a href="./Publication.html">Complete List…</a>)</h3> -->
        <div class="col-lg-12">
          <div class="row paper-box">
            <div class="col-md-3 col-12 paper_img"> 
              <video 
                src="projects/RhyCap/RhyCap.mp4" width="90%" playsinline=""
                autoplay="autoplay" loop="loop" preload="" muted="" alt="Popup Image" class="img-fluid" />
              </div>
       
            <div class="col-md-9 col-12 paper-content">
              <h4>	
                <strong>RhyCap</strong>: Multi-view real-time full-body mocap system<br>
              </h4>
              <p> Achieving high-quality full-body motion capture without wearable devices using even only three RGB cameras. The system has been integrated into the <a href="https://www.bilibili.com/video/BV1244y1W7j7"a>Bilibili live</a> streaming pipeline.
              </p>
              <p>
                [<a href="https://www.bilibili.com/video/BV1Ab4y1e71F/">Video</a>]
              </p>
            </div>
       
          </div>
        </div>
        <div class="col-lg-12">
          <div class="row paper-box">
            <div class="col-md-3 col-12 paper_img"> 
              <video 
                src="projects/RhyLive/RhyLive2.mp4" width="90%" playsinline=""
                autoplay="autoplay" loop="loop" preload="" muted="" alt="Popup Image" class="img-fluid" />
              </div>
       
            <div class="col-md-9 col-12 paper-content">
              <h4>	
                <strong>RhyLive</strong>: Virtual live via monocular face-body-hands performance capture <br>
              </h4>
              <p>
                Achieving fine-grained capture of the upper body, face, and hands using a single camera. The system has been integrated into the <a href="https://www.bilibili.com/video/BV1jZ4y1Q74X"a>Bilibili live</a> streaming pipeline.
              </p>
              <p>
                [<a href="https://www.bilibili.com/video/BV1Xg411K7wY/">Video</a>]
              </p>
            </div>
       
          </div>
        </div>
      </div>
    </section>

    <!-- experience -->
    <section class="wedo" id="experience">
      <h3 class="w3_head mb-5">Education</h3>
        <div class="row service_w3top mt-5">
          <div class="col-xl-12">
            <div class="d-flex experience-box">
              <div class="icon"> <span class="fa fa-graduation-cap"></span> </div>
              <!-- .Icon ends here -->
              <div class="service-content">
                <div class="d-md-flex justify-content-between">
                  <h4><a href="http://www.shanghaitech.edu.cn/eng/">ShanghaiTech University - 上海科技大学</a></h4>
                  <h4>Sep. 2020 - Present </h4>
                </div>
                <h4> Ph.D Candidate</h4>
                <p>I am now a PhD candidate on digital human research, advised by <a
                  href="http://www.xu-lan.com/">Prof. Lan Xu</a> and <a
                  href="http://www.yu-jingyi.com/">Prof. Jingyi Yu</a>.</p>
                <br>
              </div>
              <!-- .Service-content ends here -->
            </div>
            <div class="d-flex experience-box">
              <div class="icon"> <span class="fa fa-graduation-cap"></span> </div>
              <!-- .Icon ends here -->
              <div class="service-content">
                <div class="d-md-flex justify-content-between">
                  <h4><a href="http://english.upc.edu.cn/">UESTC - 电子科技大学</a></h4>
                  <h4>Sep. 2014 - Jul. 2018 </h4>
                </div>
                <h4> Bachelor </h4>
                <p>I obtained my B.E. in software engineering from <a
                  href="https://en.uestc.edu.cn/">University of Electronic Science and Technology of China</a>.</p><br><br>
              </div>
              <!-- .Service-content ends here -->
            </div>
          </div>
        </div>
      <div class="experience">
        <h3 class="w3_head mb-5">Experience</h3>
        <div class="row service_w3top mt-5">
          <div class="col-xl-12">
            <div class="d-flex experience-box">
              <div class="icon"><span class="fa fa-briefcase"></span> </div>
              <!-- .Icon ends here -->
              <div class="service-content">
                <div class="d-md-flex justify-content-between">
                  <h4><a href="https://www.dgene.com/eng/">DGene Inc. - 上海叠境数字科技有限公司</a></h4>
                  <h4> Jun. 2021 - May. 2022</h4>
                </div>
                <h4> Reseach Intern</h4>
                <p>I worked as a research intern at <a href="https://www.dgene.com/eng/">DGene
                    Digital Technology Inc. </a></p>
                <br>
              </div>
              <!-- .Service-content ends here -->
            </div>
            <div class="d-flex experience-box">
              <div class="icon"><span class="fa fa-briefcase"></span> </div>
              <!-- .Icon ends here -->
              <div class="service-content">
                <div class="d-md-flex justify-content-between">
                  <h4><a href="http://www.dilusense.com/">Dilusense Inc. - 北京的卢深视科技有限公司</a></h4>
                  <h4> Jul. 2018 - Jun. 2020</h4>
                </div>
                <h4> 3D Vision R&amp;D Engineer</h4>
                <p>I joined <a href="http://www.dilusense.com/">Dilusense Inc. </a>, where I worked closely with <a href="http://staff.ustc.edu.cn/~juyong/">Prof. Juyong Zhang</a>. </p>
                <br>
              </div>
              <!-- .Service-content ends here -->
            </div>
            <div class="d-flex experience-box">
              <div class="icon"><span class="fa fa-briefcase"></span> </div>
              <!-- .Icon ends here -->
              <div class="service-content">
                <div class="d-md-flex justify-content-between">
                  <h4><a href="https://en.ustc.edu.cn/">USTC - 中国科学技术大学</a></h4>
                  <h4> Oct. 2017 - Jun. 2018</h4>
                </div>
                <h4> Visiting Student</h4>
                <p>I visited the <a href="http://gcl.ustc.edu.cn/en/">GCL Lab </a> in <a href="https://en.ustc.edu.cn/">University of Science and Technology of China </a> for 9 months, hosted by <a href="http://staff.ustc.edu.cn/~lgliu/">Prof. Ligang Liu</a>. </p>
                <br>
              </div>
              <!-- .Service-content ends here -->
            </div>
          </div>
        </div>
        
      </div>
    </section>



        <!-- Supervisors -->
    <!-- <section class="wedo" id="-Supervisors">
      <h3 class="w3_head col-md-12 mb-12"> Co-authors </h3>
      <div id="id4" style="clear:both"></div>
      <div class="col-md-5 col-12 people-content">
        <p class="banp mt-5"> <a href="http://www.yu-jingyi.com/">Prof. Jingyi Yu</a> - Supervisor </p>
        <li>IEEE Fellow</li>
        <li>Program chair of ICPR 2020 and CVPR 2021</li>
        <li>Executive Dean, SIST, ShanghaiTech University</li>
        <li>Founder, DGene Inc.</li>
        <li>Ph.D.'s degree, MIT, 2005</li>
      </div>

      <div id="id4" style="clear:both"></div>
    </section> -->

    <!-- //skill -->
    <section class="wedo" id="skill">
      <h3 class="w3_head mb-1">Skills </h3>
      <p class="banp mt-5"> Programming Languages</p>
      <ul class="fa-ul mb-0">
        <li> <i class="fa-li fa fa-check"></i> Python (Pytorch, Pearl, and so on.)</li>
        <li> <i class="fa-li fa fa-check"></i> C++ (OpenCV, CUDA and so on. )</li>
      </ul>
      <p class="banp mt-5"> Softwares</p>
      <ul class="fa-ul mb-0">
        <li> <i class="fa-li fa fa-check"></i> Visual Studio, Pycharm, Jupyter Notebook</li>
        <li> <i class="fa-li fa fa-check"></i> Unity, Blender, Maya</li>
        <li> <i class="fa-li fa fa-check"></i> Adobe Photoshop, Premiere</li>
      </ul>
      <p class="banp mt-5"> Others</p>
      <ul class="fa-ul mb-0">
        <li> <i class="fa-li fa fa-check"></i> Latex, Markdown</li>

      </ul>
      <!-- <script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.?i=5ix9r8rqpnb&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33" async="async"></script> -->
      <!-- <script type="text/javascript" src="//rf.revolvermaps.com/0/0/6.js?i=59qpe4r4c9p&amp;m=7&amp;c=e63100&amp;cr1=ffffff&amp;f=arial&amp;l=0&amp;bv=90&amp;lx=-420&amp;ly=420&amp;hi=20&amp;he=7&amp;hc=a8ddff&amp;rs=80" async="async"></script> -->
    </section>
    <!-- //skill -->
  </div>
  <script>
	var newsBoxMoreBtn = document.getElementById('news-box-more')
	var newsBox = document.getElementById('news-box');
	var flag = false;
	newsBoxMoreBtn.addEventListener('click',function(){
		flag = !flag;
		if(flag){
			newsBox.style.height = 'auto';
			newsBoxMoreBtn.innerHTML = 'CLOSE <<'
		}
		else{
			newsBox.style.height = '75px';
			newsBoxMoreBtn.innerHTML = 'MORE >>'
		}
		
	})
  </script>
</body>

</html>